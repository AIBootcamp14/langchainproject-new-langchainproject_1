from __future__ import annotations

from typing import Dict, List, Literal, Optional, TypedDict, Annotated

from langgraph.graph import END, StateGraph
from langgraph.graph.message import add_messages

from src.agents.financial_analyst import FinancialAnalyst
from src.agents.quality_evaluator import QualityEvaluator
from src.agents.report_generator import ReportGenerator
from src.agents.request_analyst import request_analysis, rewrite_query
from src.agents.supervisor import supervisor
from src.model.llm import get_llm_manager
from src.rag.retriever import Retriever
from src.utils.config import Config

from src.utils.logger import get_logger

logger = get_logger(__name__)


class WorkflowState(TypedDict, total=False):
    """LangGraphì—ì„œ ì£¼ê³ ë°›ëŠ” ê¸°ë³¸ ìƒíƒœ êµ¬ì¡°.

    *** ê°œì¸ì ìœ¼ë¡œ í•„ìš”í•œ ìƒíƒœ ê°’ë“¤ì€ ì•„ë˜ì— ì£¼ì„ê³¼ í•¨ê»˜ ì¶”ê°€ ë¶€íƒë“œë¦¬ê² ìŠµë‹ˆë‹¤.***

    """
    session_id: str # ì‚¬ìš©ì ì„¸ì…˜ id
    question: str # ì‚¬ìš©ìì˜ ì§ˆë¬¸
    answer: str   # LLM ì˜ ìƒì„± ë‹µë³€
    route: Literal["end", "supervisor", "financial_analyst", "report_generator"]
    request_type: Literal["rag", "financial_analyst"]  # report_generator ì˜ 2ê°€ì§€ task ë¶„ê¸°
    rag_search_results: List[str]  # Rag ì˜ ê²€ìƒ‰ ê²°ê³¼
    analysis_data: Dict[str, object] # Rag í˜¹ì€ financial_analyst ì˜ ìµœì¢… ë¶„ì„ ê²°ê³¼
    quality_passed: bool       # quality_evaluator ì—ì„œì˜ í’ˆì§ˆ í†µê³¼ ì—¬ë¶€
    quality_detail: Dict[str, object]  # quality_evaluator ì˜ í‰ê°€ ê²°ê³¼ ë””í…Œì¼
    retries : int  # ë£¨í”„ ì¬ì‹œë„ íšŸìˆ˜
    previous_failure_reason: str  # ì´ì „ ì‹¤íŒ¨ ì´ìœ  (ì—°ì† ì‹¤íŒ¨ ê°ì§€ìš©)
    consecutive_same_failures: int  # ë™ì¼ ì‹¤íŒ¨ ì—°ì† íšŸìˆ˜
    messages : Annotated[list, add_messages]
    agent_scratchpad : Annotated[list, add_messages]
    # í˜„ì¬ ì‘ë‹µì—ì„œ ìƒì„±ëœ íŒŒì¼ (streamlit í‘œì‹œìš©)
    current_charts: List[str]
    current_saved_file: str
    


class Workflow:
    """ìš”ì²­ ë¶„ì„ â†’ ë¼ìš°íŒ… â†’ ë‹µë³€ ìƒì„± â†’ í’ˆì§ˆ í‰ê°€ â†’ (ì„ íƒ:ì¬ì‹œë„ ë£¨í”„) ê¹Œì§€ ì´ì–´ì§€ëŠ” ì›Œí¬í”Œë¡œìš°."""

    def __init__(self):
        self.llm_manager = get_llm_manager()
        self.shared_llm = self.llm_manager.get_model(Config.LLM_MODEL, temperature=Config.LLM_TEMPERATURE)

        self.retriever = Retriever()
        self.financial_analyst = FinancialAnalyst()
        self.report_generator = ReportGenerator()
        self.quality_evaluator = QualityEvaluator(llm=self.shared_llm)
        self.graph = self._build_graph()

   
    def _build_graph(self):
        graph = StateGraph(WorkflowState)

        graph.add_node("request_analyst", self.request_analyst_node)
        graph.add_node("supervisor", self.supervisor_node)
        graph.add_node("financial_analyst", self.financial_analyst_node)
        graph.add_node("general_conversation", self.general_conversation_node)
        graph.add_node("report_generator", self.report_generator_node)
        graph.add_node("quality_evaluator", self.quality_evaluator_node)

        graph.set_entry_point("request_analyst")

        graph.add_conditional_edges(
            "request_analyst",
            self._route_from_request_analyst,
            {
                "end": END,
                "supervisor": "supervisor",
                "report_generator": "report_generator",
            },
        )

        graph.add_conditional_edges(
            "supervisor",
            self._route_from_supervisor,
            {
                "financial_analyst": "financial_analyst",
                "report_generator": "report_generator",
                "general_conversation": "general_conversation",
                "end": END,
            },
        )

        graph.add_edge("financial_analyst", "report_generator")
        graph.add_edge("general_conversation", END)  # ì¼ë°˜ ëŒ€í™”ëŠ” ë°”ë¡œ ì¢…ë£Œ
        graph.add_edge("report_generator", "quality_evaluator")

        graph.add_conditional_edges(
            "quality_evaluator",
            self._route_from_quality_evaluator,
            {
                "retry": "request_analyst",
                "end": END,
            },
        )

        return graph.compile()

    # ------------------------------------------------------------------ #
    # Node 
    # ------------------------------------------------------------------ #
    def request_analyst_node(self, state: WorkflowState) -> WorkflowState:
        """ì§ˆë¬¸ì´ ê²½ì œ, ê¸ˆìœµ ë„ë©”ì¸ì¸ì§€ í™•ì¸í•˜ê³  ë¹„ê¸ˆìœµì´ë©´ ë°”ë¡œ END ë¡œ ì¢…ë£Œë©ë‹ˆë‹¤."""
        question = state.get("question", "").strip()
        if not question:
            state["answer"] = "ì§ˆë¬¸ì´ ë¹„ì–´ ìˆì–´ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            state["route"] = "end"
            return state

        # í›„ì† ì§ˆë¬¸ ê°ì§€ (PDF ì €ì¥, ì°¨íŠ¸ ìƒì„± ë“±)
        has_previous_analysis = state.get("analysis_data") is not None
        follow_up_keywords = ["ê·¸ë˜í”„", "ì°¨íŠ¸", "ì €ì¥", "ê·¸ë ¤", "ë‹¤ìš´ë¡œë“œ", "íŒŒì¼", "pdf", "md", "markdown", "ë³´ê³ ì„œ"]
        is_follow_up = any(keyword in question.lower() for keyword in follow_up_keywords)

        if has_previous_analysis and is_follow_up:
            logger.info(f"ğŸ“Š í›„ì† ì§ˆë¬¸ ê°ì§€ (request_analyst ìš°íšŒ) - ì´ì „ ë¶„ì„ ë°ì´í„°ë¡œ ë°”ë¡œ report_generator í˜¸ì¶œ")
            state["route"] = "report_generator"
            state["request_type"] = "financial_analyst"
            return state

        # ì¼ë°˜ì ì¸ ê¸ˆìœµ ì§ˆë¬¸ ë¶„ì„
        analysis_result = request_analysis(state, llm=self.shared_llm)
        label = analysis_result.get("label")
        if label == "finance":
            state["route"] = "supervisor"
        else:
            # ë¹„ê¸ˆìœµ ì§ˆë¬¸ì¸ ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬
            state["answer"] = analysis_result.get("return_msg", "ê²½ì œ, ê¸ˆìœµê´€ë ¨ ì§ˆë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤.")
            state["route"] = "end"
        return state

    def supervisor_node(self, state: WorkflowState) -> WorkflowState:
        """ìŠˆí¼ë°”ì´ì € ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•´ ë‹¤ìŒ ë…¸ë“œë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
        # ì¼ë°˜ì ì¸ ë¼ìš°íŒ…
        agent_choice = supervisor(
            state,
            llm=self.shared_llm,
        )

        if agent_choice == "financial_analyst":
            state["route"] = "financial_analyst"
        elif agent_choice == "vector_search_agent":
            state["route"] = "report_generator"
            state["request_type"] = "rag"
        else:  # "none" - ì¼ë°˜ ëŒ€í™”, ì¸ì‚¬, ë©”íƒ€ ì§ˆë¬¸ ë“±
            logger.info("ğŸ’¬ ì¼ë°˜ ëŒ€í™”ë¡œ ë¼ìš°íŒ… (general_conversation)")
            state["route"] = "general_conversation"
        return state

    def financial_analyst_node(self, state: WorkflowState) -> WorkflowState:
        """ì¬ë¬´ ë¶„ì„ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰ í›„, report_generatorë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
        question = state.get("question", "")
        messages = state.get('messages', [])
        logger.info(f"ğŸ” financial_analyst_node ì‹œì‘")

        try:
            analysis_data = self.financial_analyst.analyze(query=question, messages=messages)
            # ì¤‘ìš”: ë°˜í™˜ê°’ í™•ì¸
            logger.info(f"ğŸ“Š analyze() ë°˜í™˜ íƒ€ì…: {type(analysis_data)}")
            logger.debug(f"ğŸ“Š analyze() ë°˜í™˜ ê°’: {analysis_data}")

            # ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
            if not analysis_data or not isinstance(analysis_data, dict):
                logger.error("âŒ financial_analystê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° ë°˜í™˜")
                state["answer"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì£¼ì‹ ë¶„ì„ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                state["route"] = "end"
                return state

            state["analysis_data"] = analysis_data
            state["request_type"] = "financial_analyst"
            logger.info(f"âœ… stateì— ì €ì¥ ì™„ë£Œ")
            logger.debug(f"âœ… state['analysis_data'] í™•ì¸: {state.get('analysis_data', 'NOT FOUND')}")

        except Exception as e:
            logger.error(f"âŒ financial_analyst_node ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            state["answer"] = f"ì£¼ì‹ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            state["route"] = "end"

        return state

    def general_conversation_node(self, state: WorkflowState) -> WorkflowState:
        """ì¼ë°˜ ëŒ€í™”, ì¸ì‚¬, ê°ì‚¬, ë©”íƒ€ ì§ˆë¬¸ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        question = state.get("question", "").strip()
        question_lower = question.lower()
        messages = state.get("messages", [])

        logger.info(f"ğŸ’¬ general_conversation_node ì‹œì‘ - question: {question}")

        # 1ë‹¨ê³„: ê·œì¹™ ê¸°ë°˜ íŒ¨í„´ ë§¤ì¹­ (ë¹ ë¥¸ ì‘ë‹µ, LLM ë¹„ìš© ì ˆê°)
        greetings = ["ì•ˆë…•", "í•˜ì´", "hi", "hello", "í—¬ë¡œ"]
        thanks = ["ê³ ë§ˆ", "ê°ì‚¬", "thanks", "thank you", "ë•¡í"]
        goodbyes = ["ì˜ê°€", "ì•ˆë…•íˆ", "bye", "goodbye", "ë°”ì´"]

        if any(g in question_lower for g in greetings):
            state["answer"] = "ì•ˆë…•í•˜ì„¸ìš”! ê¸ˆìœµ ê´€ë ¨ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”. ğŸ“Š"
            state["route"] = "end"
            logger.info("ğŸ’¬ ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ: ì¸ì‚¬")
            return state

        if any(t in question_lower for t in thanks):
            state["answer"] = "ë„ì›€ì´ ë˜ì—ˆë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤! ë‹¤ë¥¸ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”. ğŸ˜Š"
            state["route"] = "end"
            logger.info("ğŸ’¬ ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ: ê°ì‚¬")
            return state

        if any(gb in question_lower for gb in goodbyes):
            state["answer"] = "ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”! ì–¸ì œë“  ë‹¤ì‹œ ì°¾ì•„ì£¼ì„¸ìš”. ğŸ‘‹"
            state["route"] = "end"
            logger.info("ğŸ’¬ ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ: ì‘ë³„")
            return state

        # 2ë‹¨ê³„: ë©”íƒ€ ì§ˆë¬¸ ì²˜ë¦¬ (ëŒ€í™” íˆìŠ¤í† ë¦¬ ì°¸ì¡°)
        from langchain_core.messages import HumanMessage, AIMessage
        meta_patterns = ["ë°©ê¸ˆ", "ì•„ê¹Œ", "ì „ì—", "ì²˜ìŒ", "ì²«", "ì´ì „"]

        if any(mp in question_lower for mp in meta_patterns):
            # messagesì—ì„œ HumanMessageë§Œ ì¶”ì¶œ
            user_messages = [msg for msg in messages if isinstance(msg, HumanMessage)]

            if len(user_messages) >= 1:  # ì´ì „ ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´
                prev_question = user_messages[-1].content  # ê°€ì¥ ìµœê·¼ ì‚¬ìš©ì ì§ˆë¬¸
                state["answer"] = f'ë°©ê¸ˆ ë¬¼ì–´ë³´ì‹  ì§ˆë¬¸ì€ "{prev_question}" ì…ë‹ˆë‹¤.'
                state["route"] = "end"
                logger.info(f"ğŸ’¬ ë©”íƒ€ ì§ˆë¬¸ ì²˜ë¦¬: ì´ì „ ì§ˆë¬¸ ì¸ìš© - {prev_question[:50]}")
                return state
            else:
                state["answer"] = "ì´ì „ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ì§€ê¸ˆ ì²˜ìŒ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì‹  ê²ƒ ê°™ë„¤ìš”!"
                state["route"] = "end"
                logger.info("ğŸ’¬ ë©”íƒ€ ì§ˆë¬¸ ì²˜ë¦¬: ì´ì „ ì§ˆë¬¸ ì—†ìŒ")
                return state

        # 3ë‹¨ê³„: LLM ê¸°ë°˜ ì¼ë°˜ ëŒ€í™” (ë³µì¡í•œ ê²½ìš°)
        try:
            logger.info("ğŸ’¬ LLM ê¸°ë°˜ ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬ ì‹œì‘")
            llm_manager = get_llm_manager()
            llm = llm_manager.get_model("solar-mini", temperature=0.7)
            prompt = llm_manager.get_prompt("general_conversation")

            # í”„ë¡¬í”„íŠ¸ ì²´ì¸ ì‹¤í–‰ (MessagesPlaceholderê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬)
            chain = prompt | llm
            response = chain.invoke({"input": question, "chat_history": messages})

            state["answer"] = response.content.strip()
            state["route"] = "end"
            logger.info(f"ğŸ’¬ LLM ì‘ë‹µ ìƒì„± ì™„ë£Œ - ê¸¸ì´: {len(state['answer'])}ì")

        except Exception as e:
            logger.error(f"âŒ general_conversation_node LLM ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            state["answer"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            state["route"] = "end"

        return state

    def report_generator_node(self, state: WorkflowState) -> WorkflowState:
        """RAG ê²€ìƒ‰ í˜¹ì€ report ì‘ì„±ì„ ìˆ˜í–‰í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        question = state.get("question", "")
        messages = state.get('messages', [])
        logger.info(f"ğŸ“ report_generator_node ì§„ì…")
        logger.info(f"ğŸ“ request_type: {state.get('request_type', 'NOT SET')}")
        
        if state.get("request_type","rag") == "rag":
            logger.info("ğŸ“ RAG ëª¨ë“œ")
            results = self.retriever.retrieve(question)

            # RAG ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ financial_analystë¡œ í´ë°±
            if not results or len(results) == 0:
                logger.warning("âš ï¸ RAG ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. financial_analystë¡œ í´ë°± ì‹œë„...")

                # financial_analystë¥¼ ì§ì ‘ í˜¸ì¶œí•´ì„œ ì›¹ ê²€ìƒ‰ ì‹œë„
                try:
                    analysis_data = self.financial_analyst.analyze(query=question, messages = messages)

                    if analysis_data and isinstance(analysis_data, dict):
                        logger.info("âœ… financial_analyst í´ë°± ì„±ê³µ")
                        state["analysis_data"] = analysis_data
                        state["request_type"] = "financial_analyst"
                        # ì´ì œ ì•„ë˜ else ë¸”ë¡ì—ì„œ ì²˜ë¦¬ë¨
                    else:
                        logger.error("âŒ financial_analyst í´ë°± ì‹¤íŒ¨ - ë¶„ì„ ë°ì´í„° ì—†ìŒ")
                        state["answer"] = (
                            "ì£„ì†¡í•©ë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ì™€ ì›¹ ê²€ìƒ‰ ëª¨ë‘ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                            "ë‹¤ë¥¸ ì£¼ì œë¡œ ì§ˆë¬¸í•´ì£¼ì‹œê±°ë‚˜, ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
                        )
                        return state

                except Exception as e:
                    logger.error(f"âŒ financial_analyst í´ë°± ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
                    state["answer"] = (
                        "ì£„ì†¡í•©ë‹ˆë‹¤. ì •ë³´ë¥¼ ì°¾ëŠ” ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n"
                        "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                    )
                    return state
            else:
                # RAG ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
                rag_search_results = []
                for doc, score in results:
                    page = doc.metadata.get("page", "?")
                    if isinstance(page, int):
                        page += 1  # 0-index â†’ 1-index ë³€í™˜
                    source = doc.metadata.get("source", "unknown")
                    rag_search_results.append(f"- (score={score:.2f}) {source} p.{page}")

                state["rag_search_results"] = rag_search_results

                analysis_data = {
                "analysis_type" : "rag",
                "query": question,
                "documents": [doc.page_content for doc, _ in results],
                }

                state["analysis_data"] = analysis_data

        else:
            # financial_analyst ì—ì„œ í˜¸ì¶œ ì‹œ, í•´ë‹¹ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©
            logger.info("ğŸ“ financial_analyst ëª¨ë“œ")
            analysis_data = state.get("analysis_data")
            if not analysis_data:
                logger.error("âŒ analysis_dataê°€ stateì— ì—†ìŠµë‹ˆë‹¤!")
                state["answer"] = "ë¶„ì„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                return state

            logger.debug(f"âœ… State ì €ì¥ì†Œ analysis_data ë¡œë“œ: {analysis_data.get('analysis_type', 'N/A')}")

        # ë³´ê³ ì„œ ìƒì„± with ì—ëŸ¬ ì²˜ë¦¬
        try:
            report = self.report_generator.generate_report(user_request=question, analysis_data=analysis_data, messages = messages)

            if not report or not isinstance(report, dict):
                logger.error("âŒ report_generatorê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° ë°˜í™˜")
                state["answer"] = "ë³´ê³ ì„œ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                return state

            state["answer"] = report.get("report", "ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            logger.info(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(state['answer'])})")

            # í˜„ì¬ ì‘ë‹µì—ì„œ ìƒì„±ëœ ì°¨íŠ¸/íŒŒì¼ ì €ì¥
            if report.get("charts"):
                state["current_charts"] = report["charts"]
                logger.info(f"ğŸ“Š í˜„ì¬ ì‘ë‹µ ì°¨íŠ¸ ì €ì¥: {report['charts']}")
            else:
                state["current_charts"] = []  # ì°¨íŠ¸ ìƒì„± ì•ˆ í–ˆìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸

            if report.get("saved_path"):
                state["current_saved_file"] = report["saved_path"]
                logger.info(f"ğŸ’¾ í˜„ì¬ ì‘ë‹µ íŒŒì¼ ì €ì¥: {report['saved_path']}")
            else:
                state["current_saved_file"] = None

            # analysis_dataëŠ” ë‹¤ìŒ í›„ì† ì§ˆë¬¸ì„ ìœ„í•œ ì°¸ì¡°ìš©ìœ¼ë¡œ ìœ ì§€
            if report.get("charts") or report.get("saved_path"):
                if "analysis_data" not in state:
                    state["analysis_data"] = {}

                if report.get("charts"):
                    state["analysis_data"]["chart_paths"] = report["charts"]

                if report.get("saved_path"):
                    state["analysis_data"]["saved_file_path"] = report["saved_path"]

        except Exception as e:
            logger.error(f"âŒ ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            state["answer"] = f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

        return state

    def quality_evaluator_node(self, state: WorkflowState) -> WorkflowState:
        """ìƒì„±ëœ ë‹µë³€ì„ í‰ê°€í•˜ê³  í•„ìš” ì‹œ ì¿¼ë¦¬ë¥¼ ì¬ì‘ì„±í•©ë‹ˆë‹¤."""
        question = state.get("question", "")
        answer = state.get("answer", "")
        result = self.quality_evaluator.evaluate_answer(question, answer)

        state["quality_detail"] = result
        state["quality_passed"] = result.get("status") == "pass"

        if not state["quality_passed"]:
            current_failure = result.get("failure_reason", "unknown")
            previous_failure = state.get("previous_failure_reason", "")

            # ì—°ì† ë™ì¼ ì‹¤íŒ¨ ê°ì§€
            if current_failure == previous_failure:
                state["consecutive_same_failures"] = state.get("consecutive_same_failures", 0) + 1
            else:
                state["consecutive_same_failures"] = 1

            state["previous_failure_reason"] = current_failure
            state["retries"] = state.get("retries", 0) + 1
            if state['retries'] >= 2:
                logger.warning(
                    f"âš ï¸ ì‹¤íŒ¨ íšŸìˆ˜ê°€ {state['retries']}íšŒ ë°˜ë³µë¨ì—ë„ ë¶ˆêµ¬í•˜ê³  ê¸°ì¤€ ë¯¸ë§Œ ë‹µë³€ìƒì„±ìœ¼ë¡œ ì¸í•˜ì—¬ ì¡°ê¸° ì¢…ë£Œ."
                )
                state['answer'] = (
                    "ì£„ì†¡í•©ë‹ˆë‹¤. ì—¬ëŸ¬ ì‹œë„ì—ë„ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\n"
                    "ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì‹œê±°ë‚˜, ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í‘œí˜„í•´ì£¼ì‹œë©´ ë” ë‚˜ì€ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
                state['route'] = 'end'
                return state
                

            # ê°™ì€ ì´ìœ ë¡œ 2ë²ˆ ì´ìƒ ì‹¤íŒ¨í•˜ë©´ ì¡°ê¸° ì¢…ë£Œ
            if state["consecutive_same_failures"] >= 2:
                logger.warning(
                    f"âš ï¸ ë™ì¼í•œ ì‹¤íŒ¨ ì‚¬ìœ  ({current_failure})ê°€ {state['consecutive_same_failures']}íšŒ ë°˜ë³µë¨. ì¡°ê¸° ì¢…ë£Œ."
                )
                state["answer"] = (
                    "ì£„ì†¡í•©ë‹ˆë‹¤. ì—¬ëŸ¬ ì‹œë„ì—ë„ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\n"
                    "ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì‹œê±°ë‚˜, ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í‘œí˜„í•´ì£¼ì‹œë©´ ë” ë‚˜ì€ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
                state["route"] = "end"

                if current_failure == "error":
                    state["answer"] = (
                        "ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì—ì„œ í•´ë‹¹ ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ë° ë°˜ë³µì ìœ¼ë¡œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n"
                        "ë‹¤ìŒì„ ì‹œë„í•´ë³´ì„¸ìš”:\n"
                        "1. ì§ˆë¬¸ì„ ë‹¤ë¥´ê²Œ í‘œí˜„í•´ì£¼ì„¸ìš”\n"
                        "2. ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš” (ì˜ˆ: íšŒì‚¬ëª…, ë‚ ì§œ ë“±)\n"
                        "3. ë‹¤ë¥¸ ì£¼ì œë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”"
                    )
                else:
                    state["answer"] = (
                        "ì£„ì†¡í•©ë‹ˆë‹¤. ì—¬ëŸ¬ ì‹œë„ì—ë„ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\n"
                        "ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì‹œê±°ë‚˜, ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í‘œí˜„í•´ì£¼ì‹œë©´ ë” ë‚˜ì€ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    )
                state["route"] = "end"
                return state

            rewrite_result = rewrite_query(
                original_query=question,
                failure_reason=current_failure,
                llm=self.shared_llm,
            )
            logger.info(
                "quality_evaluator_node ê²°ê³¼ | needs_user_input=%s | rewritten_query=%s",
                rewrite_result.get("needs_user_input"),
                rewrite_result.get("rewritten_query"),
            )

            if rewrite_result.get("needs_user_input"):
                state["answer"] = rewrite_result.get(
                    "request_for_detail_msg", "ì§ˆë¬¸ì„ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”? "
                )
                state["route"] = "end"
            else:
                state["question"] = rewrite_result.get("rewritten_query", question)
                state["answer"] = "ì§ˆë¬¸ì„ ë‹¤ì‹œ ì •ì œí–ˆìŠµë‹ˆë‹¤. ì¬ì‹œë„í•©ë‹ˆë‹¤."
                state["route"] = "retry"  
        else:
            # ì„±ê³µ ì‹œ ëª¨ë“  ì¹´ìš´í„° ì´ˆê¸°í™”
            state["retries"] = 0
            state["consecutive_same_failures"] = 0
            state["previous_failure_reason"] = ""
            state['route'] = 'end'

        return state

    # ------------------------------------------------------------------ #
    # Edge routing helpers
    # ------------------------------------------------------------------ #
    def _route_from_request_analyst(self, state: WorkflowState) -> Literal["end", "supervisor", "report_generator"]:
        """
        request_analystì—ì„œ ë‹¤ìŒ ë…¸ë“œë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.
        - í›„ì† ì§ˆë¬¸(ì°¨íŠ¸/PDF ìš”ì²­) â†’ report_generatorë¡œ ì§í–‰
        - ê¸ˆìœµ ì§ˆë¬¸ â†’ supervisor
        - ë¹„ê¸ˆìœµ ì§ˆë¬¸ â†’ end
        """
        route = state.get("route", "supervisor")
        if route == "report_generator":
            logger.info("ğŸ¯ request_analyst â†’ report_generator ì§í–‰ (í›„ì† ì§ˆë¬¸)")
            return "report_generator"
        elif route == "end":
            return "end"
        else:
            return "supervisor"

    def _route_from_supervisor(self, state: WorkflowState) -> Literal["financial_analyst", "report_generator", "general_conversation", "end"]:
        return state.get("route", "financial_analyst")

    def _route_from_quality_evaluator(self, state: WorkflowState) -> Literal["retry", "end"]:
        """
        í’ˆì§ˆ í‰ê°€ ê²°ê³¼ì— ë”°ë¼ ì¬ì‹œë„ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
        ìµœëŒ€ 3íšŒê¹Œì§€ë§Œ ì¬ì‹œë„í•˜ë©°, ì´í›„ì—ëŠ” ê°•ì œë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.
        """
        route = state.get("route", "end")
        logger.info(f"í’ˆì§ˆ í‰ê°€ í›„ ë¼ìš°íŒ…: {route}")
        return route  

    # ------------------------------------------------------------------ #
    # Public API
    # ------------------------------------------------------------------ #
    def run(
        self,
        question: str,
        previous_messages: list = None,
        previous_analysis_data: dict = None,
        session_id: str = None
    ) -> WorkflowState:
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ë”°ë¥¸ ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•œ ë’¤ ìµœì¢… ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # ì§ˆë¬¸ ì‹œì‘ êµ¬ë¶„ì„ 
        logger.info("=" * 80)
        logger.info(f"ğŸ”µ ìƒˆë¡œìš´ ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: {question[:50]}..." if len(question) > 50 else f"ğŸ”µ ìƒˆë¡œìš´ ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: {question}")
        logger.info("=" * 80)

        # State ì´ˆê¸°í™” - ëª¨ë“  í•„ë“œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì´ˆê¸°í™”
        initial_state: WorkflowState = {
            "question": question,
            "answer": "",
            "route": "",
            "retries": 0,  # ì¬ì‹œë„ ì¹´ìš´í„° ì´ˆê¸°í™”
            "quality_passed": False,
            "rag_search_results": [],
            "consecutive_same_failures": 0,  # ì—°ì† ì‹¤íŒ¨ ì¹´ìš´í„° ì´ˆê¸°í™”
            "previous_failure_reason": "",  # ì´ì „ ì‹¤íŒ¨ ì´ìœ  ì´ˆê¸°í™”
            "messages": previous_messages if previous_messages is not None else []
        }

        # ì´ì „ ë¶„ì„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ stateì— ì¶”ê°€ (í›„ì† ì§ˆë¬¸ ê°ì§€ìš©)
        if previous_analysis_data is not None:
            initial_state["analysis_data"] = previous_analysis_data
            logger.info(f"âœ… ì´ì „ ë¶„ì„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ - type: {previous_analysis_data.get('analysis_type', 'N/A')}")

        result = self.graph.invoke(initial_state)

        # ì§ˆë¬¸ ì¢…ë£Œ êµ¬ë¶„ì„ 
        logger.info("=" * 80)
        logger.info(f"ğŸŸ¢ ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ - route: {result.get('route')}, quality_passed: {result.get('quality_passed')}, retries: {result.get('retries', 0)}")
        logger.info("=" * 80)
        logger.info("")  # ë¹ˆ ì¤„ ì¶”ê°€

        return result


def build_workflow() -> Workflow:
    """ì™¸ë¶€ì—ì„œ ê°„í¸í•˜ê²Œ ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•  ë•Œ ì‚¬ìš©."""
    return Workflow()


__all__ = ["Workflow", "WorkflowState", "build_workflow"]


# if __name__ == "__main__":
#     # from IPython.display import Image
#     wf = build_workflow()
#     # Image(wf.graph.get_graph().draw_png())
#     mermaid_code = wf.graph.get_graph().draw_mermaid()
#     # print(wf.graph.get_graph().draw_mermaid())
#     with open("/workspace/langchain_project/img/workflow_diagram.mmd", "w", encoding="utf-8") as f:
#         f.write(mermaid_code)
#     print("ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ì´ workflow_diagram.mmd íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    workflow = build_workflow()
    sample_questions = [
        "ì‚¼ì„±ì „ìì™€ ì• í”Œì˜ ìµœê·¼ ì‹¤ì ì„ ë¹„êµí•´ì£¼ì„¸ìš”.",
        "ì• í”Œ ì£¼ì‹ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì°¨íŠ¸ì™€ í•¨ê»˜ PDFë¡œ ì €ì¥í•´ì¤˜. íŒŒì¼ëª…ì€ ë„ˆê°€ ìƒê°í•´ì„œ ì ì ˆí•œ ê±¸ ì •í•´ì¤˜.",
        "ë‚´ì¼ ë‚ ì”¨ëŠ” ë­ì•¼?",
        "ë ˆë²„ë¦¬ì§€ ETFì˜ ìœ„í—˜ì„±ì„ ì„¤ëª…í•´ì¤˜",
        "í…ŒìŠ¬ë¼ ì£¼ì‹ì„ ë¶„ì„í•´ì„œ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥í•´ì¤˜. ì ì ˆí•œ íŒŒì¼ëª…ìœ¼ë¡œ.",
        "ì‚¼ì„±ì „ìì™€ ì• í”Œì˜ ìµœê·¼ ì£¼ê°€ë¥¼ ë¹„êµ í›„, ê°„ë‹¨í•˜ê²Œ ì°¨íŠ¸ë¥¼ ê·¸ë¦¬ê³  pdfíŒŒì¼ë¡œ ì €ì¥í•´ ì¤˜.",
        "ë‚˜ìŠ¤ë‹¥ì´ ë­ì•¼?",
        "ëª¨ë°”ì¼ë¡œ ì£¼ì‹ ê±°ë˜í•˜ëŠ” ì•±ì€ ë­ë¼ê³  í•´?"
    ]

    for question in sample_questions:
        print("=" * 80)
        print(f"Q: {question}")
        result = workflow.run(question)
        print(f"route: {result.get('route')}")
        answer = result.get("answer")
        if isinstance(answer, str) and len(answer) > 400:
            answer = answer[:400] + "..."
        print("answer:", answer)
        if result.get("rag_search_results"):
            print("rag_search_results:")
            for line in result["rag_search_results"]:
                print(f"  {line}")
        if result.get("quality_detail"):
            print(f"quality_check: {result['quality_detail']}")
